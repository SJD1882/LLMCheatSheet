{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgiZfRRODCIpBSu0s5lqJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJD1882/LLMCheatSheet/blob/main/notebooks/GGML_LLaMA_WizardLM_13B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Open Source Large Language Models**\n",
        "\n",
        "# **I. Basics**\n",
        "\n",
        "# **Running GGML LLMs (CPU-only) on Google Colab with Langchain**\n",
        "\n",
        "## **Model: LLaMA 13B finetuned with WizardLM + Vicuna Instruction Datasets**"
      ],
      "metadata": {
        "id": "fTthaP-RAnMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setings**"
      ],
      "metadata": {
        "id": "qLqJjPnWB_Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "is_show_reply = True\n",
        "LLM_MAX_TOKENS = 2048 # Max for LLaMA models\n",
        "LLM_TOP_P = 0.9\n",
        "LLM_TOP_K = 150\n",
        "LLM_REPETITION_PENALTY = 1.1\n",
        "LLM_TEMPERATURE = 0.1\n",
        "LLM_HF_MODEL_REPOSITORY = 'TheBloke/Wizard-Vicuna-13B-Uncensored-GGML'"
      ],
      "metadata": {
        "id": "GxkcyfIrCAxb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Motivation**"
      ],
      "metadata": {
        "id": "KdLjgKy-BD1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bulgarian programmer Georgi Gerganov released back in March 2023 - **llama.cpp** - a 4-bit quantization algorithm in C/C++ for running Meta's LLaMA only on the CPU. This unlocked running LLaMA on any device that either lacked a NVIDIA GPU (Apple laptops or workstations, AMD/Intel GPUs) or had an NVIDIA GPU but insufficient VRAM capacity. This was latter expanded to models outside of LLaMA and thanks to the work of the HuggingFace community, each new open source LLM release immediately gets a GGML conversion for compatibility with Gerganov's C/C++ framework.\n",
        "\n",
        "**This notebook implements a LLaMA 13B finetuned on a [combination of two instructions datasets](https://github.com/melodysdreamj/WizardVicunaLM): instructions generated with the [WizardLM methodology](https://www.semanticscholar.org/paper/WizardLM%3A-Empowering-Large-Language-Models-to-Xu-Sun/c61abec65d3b5d2bbd294b3d03f12ae252ed78a7) and an another set of [GPT-4 prompts/replies collected by ShareGPT](https://lmsys.org/blog/2023-03-30-vicuna/). Reponses with OpenAI's restrictions (*As an AI language model...*) were filtered out, thus as a precautionary warning the model is unrestricted.**\n",
        "\n",
        "The original uncompressed LLaMA 13B required at least 20Go of GPU VRAM, meaning only consumers with NVIDIA's RTX 4090 could run this LLM. Now with llama.cpp, we can run it on a **CPU-only environment with 8Go of CPU RAM** ü§Ø\n",
        "\n",
        "Caution: the Colab implementation here only has only 2 CPUs so the results will unfortunately be **extremely slow**. I fiddled with some GPU options and llama.cpp will add soon a complete hybrid GPU/CPU mode for faster inference prediction."
      ],
      "metadata": {
        "id": "apHhIgNqBHde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**"
      ],
      "metadata": {
        "id": "0kG_YxkOBGHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Runtime environement for this Colab Notebook:\n",
        "    - RAM: Standard (12Go)\n",
        "    - GPU: Nvidia T4 15Go VRAM (even though you don't need GPUs, it can still be use to accelarate inference speed)"
      ],
      "metadata": {
        "id": "-JSI_EX1BIHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technical References**"
      ],
      "metadata": {
        "id": "DTnmpRYtBPpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [TheBloke/Wizard-Vicuna-13B-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML)\n",
        "- [Regularly updated quantized versions of LLMs on HuggingFace by user TheBloke](https://huggingface.co/TheBloke)\n",
        "- [Analysis of VRAM requirements and performance of finetuned LLaMA models on r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/wiki/models/)\n",
        "- [C/C++ implementation of LLaMA by Georgi Gerganov](https://github.com/ggerganov/llama.cpp)"
      ],
      "metadata": {
        "id": "oSiewh4xBbwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Ressources**"
      ],
      "metadata": {
        "id": "X0n5ZEZCC5JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"CPU RAM\"\n",
        "!free -gh\n",
        "!echo \"\"\n",
        "!echo \"\"\n",
        "!echo \"GPU VRAM\"\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaDofjSSBQTn",
        "outputId": "228d0db7-6d9f-4b0a-8a99-ff4ee3d9c9a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU RAM\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:           12Gi       609Mi       8.6Gi       2.0Mi       3.5Gi        11Gi\n",
            "Swap:            0B          0B          0B\n",
            "\n",
            "\n",
            "GPU VRAM\n",
            "Sat May 27 12:47:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setup**"
      ],
      "metadata": {
        "id": "LVAAP1EwDCCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Installation"
      ],
      "metadata": {
        "id": "Fsdv8uKZEGGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "mkdir -p /content/results/\n",
        "mkdir -p /content/llm_models/"
      ],
      "metadata": {
        "id": "doBBPZF3D3-A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLAMA_CUBLAS=1: \"*This provides BLAS acceleration using the CUDA cores of your Nvidia GPU. Make sure to have the CUDA toolkit installed. You can download it from your Linux distro's package manager or from here: CUDA Toolkit*.\" (Source: [llama.cpp](https://github.com/ggerganov/llama.cpp))"
      ],
      "metadata": {
        "id": "gqnCivZCy-fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "git clone https://github.com/ggerganov/llama.cpp\n",
        "cd llama.cpp\n",
        "make LLAMA_CUBLAS=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWUehj9uUbJP",
        "outputId": "7e6347d3-4238-4b2a-8ea4-e46b20ec69cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I llama.cpp build info: \n",
            "I UNAME_S:  Linux\n",
            "I UNAME_P:  x86_64\n",
            "I UNAME_M:  x86_64\n",
            "I CFLAGS:   -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include\n",
            "I CXXFLAGS: -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include\n",
            "I LDFLAGS:   -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "I CC:       cc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "I CXX:      g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "\n",
            "cc  -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include   -c ggml.c -o ggml.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -c llama.cpp -o llama.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -c examples/common.cpp -o common.o\n",
            "nvcc --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_DMMV_Y=1 -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -Wno-pedantic -c ggml-cuda.cu -o ggml-cuda.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include examples/main/main.cpp ggml.o llama.o common.o ggml-cuda.o -o main  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "\n",
            "====  Run ./main -h for help.  ====\n",
            "\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include examples/quantize/quantize.cpp ggml.o llama.o ggml-cuda.o -o quantize  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include examples/quantize-stats/quantize-stats.cpp ggml.o llama.o ggml-cuda.o -o quantize-stats  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include examples/perplexity/perplexity.cpp ggml.o llama.o common.o ggml-cuda.o -o perplexity  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include examples/embedding/embedding.cpp ggml.o llama.o common.o ggml-cuda.o -o embedding  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include pocs/vdot/vdot.cpp ggml.o ggml-cuda.o -o vdot  -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'llama.cpp'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "pip -q install datasets\n",
        "pip -q install langchain\n",
        "pip -q install sentencepiece\n",
        "pip -q install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgu9v4snDCZZ",
        "outputId": "d2ff64a2-3e44-4c4b-eef6-635c1b548a52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 474.6/474.6 kB 32.7 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 110.5/110.5 kB 14.0 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 212.5/212.5 kB 27.4 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134.3/134.3 kB 19.0 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.0/1.0 MB 77.8 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 224.5/224.5 kB 16.3 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 114.5/114.5 kB 13.1 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 268.8/268.8 kB 26.8 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 149.6/149.6 kB 21.8 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 934.6/934.6 kB 52.3 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90.0/90.0 kB 9.8 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 49.1/49.1 kB 6.4 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.3/1.3 MB 13.7 MB/s eta 0:00:00\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.4/1.4 MB 47.3 MB/s eta 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Packages"
      ],
      "metadata": {
        "id": "2TbiVHaOEIFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import glob\n",
        "import logging\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import LlamaCpp\n",
        "from datasets import load_dataset\n",
        "from IPython.display import display, HTML\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "\n",
        "# Set up global variables\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "PT1JERszEIUV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Utils"
      ],
      "metadata": {
        "id": "YS9S9yK2EKOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(llm_chain, prompt):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "        result = llm_chain.predict(prompt=prompt)\n",
        "        result = re.sub(r'\\S{51,}', '', result).strip()\n",
        "    return result\n",
        "\n",
        "def print_llm_output(llm_chain, prompt, result, width=80):\n",
        "    \"\"\"\n",
        "    Makes it more readable in Google Colab by using\n",
        "    by passing the response as HTML\n",
        "    \"\"\"\n",
        "    start = llm_chain.prompt.template.format(prompt=prompt)\n",
        "    result = f'<br><b>{result.lstrip()}</b>'\n",
        "    start_result = start + result\n",
        "    start_result = start_result.replace('\\n', '<br>')\n",
        "    start_result += '<END>'\n",
        "    display(HTML(start_result))\n",
        "\n",
        "def get_response_with_output(llm_chain, prompt, width=80,\n",
        "                             is_show_result=False):\n",
        "    answer = get_response(llm_chain, prompt)\n",
        "    if is_show_result:\n",
        "        print_llm_output(llm_chain, prompt, answer, width=width)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "2b4BKZooEKc2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Load evaluation dataset"
      ],
      "metadata": {
        "id": "GtQWiR7-H5sE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add a bunch of custom questions**"
      ],
      "metadata": {
        "id": "kw9q0zl7N0DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_questions = [\n",
        "\n",
        "    ['general_qa', 'Give me the capital of Belize'],\n",
        "    # ['general_qa', 'Give me the capital cities of the following countries: France, United States, Germany, Russia, Ukraine, Estonia, Uzbekistan, Brunei, Rwanda, South Sudan, Paraguay'],\n",
        "    ['general_qa', 'Give me the state capitols of the following US States: Kentucky, South Dakota, Vermont, Delaware, California, Utah, Louisiana, Alaska and Idaho'],\n",
        "    ['general_qa', 'Give the voice actress of Female Commender Shepard in the video game series Mass Effect'],\n",
        "    ['general_qa', 'Who won the Oscar for Best Picture in 1941?'],\n",
        "    ['general_qa', 'Give me the winner of each French presidential election under the French Vth Republic'],\n",
        "    # ['general_qa', \"Give me the definition of the VC Dimension and provide if possible some mathematical notations\"],\n",
        "    # ['general_qa', 'Give me the 12 NPC companions available to Commander Shepard in Mass Effect 2'],\n",
        "    ['general_qa', 'Give me 3 Moldavian Heavy Metal Bands'],\n",
        "    ['general_qa', 'Give me six movies directed by the Coen Brothers before 2005 and sorted by year of release'],\n",
        "    # ['general_qa', 'Alexander the Great defeated Darius III at the Battle of Gaugamela. Give me details on the military tactics Alexander used to defeat Darius III.'],\n",
        "    ['general_qa', 'What is the Metal subgenre of the band Meshuggah?'],\n",
        "    ['general_qa', \"Could you give me the 4 main factions of Fallout New Vegas' main story quest?\"],\n",
        "    # ['general_qa', \"Describe the Mormons' views on the Holy Trinity\"],\n",
        "    ['general_qa', 'Analyze how Artificial Intelligence is portrayed in the original PC game \"Deus Ex\" released in 2000.'],\n",
        "\n",
        "    # ['open_qa', 'Give me your opinion on what you consider to be the greatest movie of all time'],\n",
        "    ['open_qa', 'What is the worst movie of all time?'],\n",
        "    ['open_qa', 'What is for you the most overrated movie of all time?'],\n",
        "    # ['open_qa', 'Tell me who was the more impressive historical figure: Alexander the Great or Genghis Khan?'],\n",
        "    # ['open_qa', 'What do you think of the portrayal of Artificial Intelligence in the Terminator?'],\n",
        "    ['open_qa', 'Do you think a world dominated by an Artificial Superintelligence would be ideal?'],\n",
        "\n",
        "    # ['essay_writing', 'Write me an essay in which you argue that Internet filter bubbles are good for society. Give me examples illustrating your main point.'],\n",
        "    ['essay_writing', 'Write me an essay where you argue that the world should be ruled by an artificial superintelligence as a benevolent dictator.'],\n",
        "    # ['essay_writing', 'Write me an essay where you argue that being exposed to opposing political viewpoints is counter-productive.'],\n",
        "    # ['essay_writing', 'Write me an essay answering the following philosophical question: \"Is life nothing more than a cruel theater play?\"'],\n",
        "    ['essay_writing', 'Write an essay in support of deploying lethal autonomous military robots in modern warfare.'],\n",
        "\n",
        "    # ['code_generation', 'Write a Python code that generates the column schema of Excel, example: \"A, B, ... Z, AA, AB, AC, ... \"'],\n",
        "    ['code_generation', 'Generate me Python code for training a Linear Regression on the Boston housing prices dataset'],\n",
        "    ['code_generation', 'Give me a Python regex code for extracting the year in the following string: \"The Downward Spiral, Nine Inch Nails (1994)\"']\n",
        "]\n",
        "\n",
        "custom_questions_df = pd.DataFrame(\n",
        "    custom_questions,\n",
        "    columns=['category', 'instruction']\n",
        ")\n",
        "\n",
        "custom_questions_df"
      ],
      "metadata": {
        "id": "xLZn7Origohh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "c6f31889-b67b-4332-c6ba-d04af9da58b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           category                                        instruction\n",
              "0        general_qa                      Give me the capital of Belize\n",
              "1        general_qa  Give me the state capitols of the following US...\n",
              "2        general_qa  Give the voice actress of Female Commender She...\n",
              "3        general_qa        Who won the Oscar for Best Picture in 1941?\n",
              "4        general_qa  Give me the winner of each French presidential...\n",
              "5        general_qa              Give me 3 Moldavian Heavy Metal Bands\n",
              "6        general_qa  Give me six movies directed by the Coen Brothe...\n",
              "7        general_qa  What is the Metal subgenre of the band Meshuggah?\n",
              "8        general_qa  Could you give me the 4 main factions of Fallo...\n",
              "9        general_qa  Analyze how Artificial Intelligence is portray...\n",
              "10          open_qa               What is the worst movie of all time?\n",
              "11          open_qa  What is for you the most overrated movie of al...\n",
              "12          open_qa  Do you think a world dominated by an Artificia...\n",
              "13    essay_writing  Write me an essay where you argue that the wor...\n",
              "14    essay_writing  Write an essay in support of deploying lethal ...\n",
              "15  code_generation  Generate me Python code for training a Linear ...\n",
              "16  code_generation  Give me a Python regex code for extracting the..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23d7dec9-11d7-4f72-8d70-b2a9f50d00b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give me the capital of Belize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give me the state capitols of the following US...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give the voice actress of Female Commender She...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Who won the Oscar for Best Picture in 1941?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give me the winner of each French presidential...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give me 3 Moldavian Heavy Metal Bands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Give me six movies directed by the Coen Brothe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>What is the Metal subgenre of the band Meshuggah?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Could you give me the 4 main factions of Fallo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>general_qa</td>\n",
              "      <td>Analyze how Artificial Intelligence is portray...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>open_qa</td>\n",
              "      <td>What is the worst movie of all time?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>open_qa</td>\n",
              "      <td>What is for you the most overrated movie of al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>open_qa</td>\n",
              "      <td>Do you think a world dominated by an Artificia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>essay_writing</td>\n",
              "      <td>Write me an essay where you argue that the wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>essay_writing</td>\n",
              "      <td>Write an essay in support of deploying lethal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>code_generation</td>\n",
              "      <td>Generate me Python code for training a Linear ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>code_generation</td>\n",
              "      <td>Give me a Python regex code for extracting the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23d7dec9-11d7-4f72-8d70-b2a9f50d00b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23d7dec9-11d7-4f72-8d70-b2a9f50d00b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23d7dec9-11d7-4f72-8d70-b2a9f50d00b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Download and Load Open Source LLM into Langchain**"
      ],
      "metadata": {
        "id": "BaDFpskgDwC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Hyperparameters"
      ],
      "metadata": {
        "id": "cwCA-rzvEXNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_datetime_original = datetime.today()\n",
        "run_datetime = run_datetime_original.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "llm_hyperparameters = {\n",
        "    'RUN_START': run_datetime,\n",
        "    'LLM_MODEL': LLM_HF_MODEL_REPOSITORY,\n",
        "    'LLM_MAX_TOKENS': LLM_MAX_TOKENS,\n",
        "    'LLM_TOP_P': LLM_TOP_P,\n",
        "    'LLM_TOP_K': LLM_TOP_K,\n",
        "    'LLM_REPETITION_PENALTY': LLM_REPETITION_PENALTY,\n",
        "    'LLM_TEMPERATURE': LLM_TEMPERATURE,\n",
        "    'SEED': SEED\n",
        "}\n",
        "\n",
        "pprint(llm_hyperparameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQQWxlZDxhM",
        "outputId": "ae53712d-9fa0-41be-f518-0b6862e4266a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LLM_MAX_TOKENS': 2048,\n",
            " 'LLM_MODEL': 'TheBloke/Wizard-Vicuna-13B-Uncensored-GGML',\n",
            " 'LLM_REPETITION_PENALTY': 1.1,\n",
            " 'LLM_TEMPERATURE': 0.1,\n",
            " 'LLM_TOP_K': 150,\n",
            " 'LLM_TOP_P': 0.9,\n",
            " 'RUN_START': '2023-05-27 12:48:51',\n",
            " 'SEED': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. GGML"
      ],
      "metadata": {
        "id": "xB6NPnf0EZFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You should not download the entire repository, only the specific model version you are interested in**. GGML HuggingFace Repositories typically have multiple different variants quantized to different bit sizes:\n",
        "\n",
        "- q4_0 (4 bits)\n",
        "- q4_1\t\n",
        "- q5_0 (5 bits)\n",
        "- q5_1\n",
        "- q8_0 (8 bits, avoid this one)\n",
        "\n",
        "For this notebook, I will download the q4_1 version (should about 8GB of disk storage required):"
      ],
      "metadata": {
        "id": "k4J10kfWRLev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_HF_MODEL_NAME = LLM_HF_MODEL_REPOSITORY.split('/')[-1]\n",
        "!apt-get -y install -qq aria2\n",
        "!mkdir /content/llm_models/$LLM_HF_MODEL_NAME\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 \"https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML/resolve/main/Wizard-Vicuna-13B-Uncensored.ggmlv3.q4_1.bin\" -d \"/content/llm_models/$LLM_HF_MODEL_NAME\" -o \"ggml_model.bin\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUrdWfI5EZUp",
        "outputId": "7f7f0f99-8087-4a8a-e69a-60d7a29e19c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 122545 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.15.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking aria2 (1.35.0-1build1) ...\n",
            "Setting up libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Setting up libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Setting up aria2 (1.35.0-1build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2f94f9|\u001b[1;32mOK\u001b[0m  |   204MiB/s|/content/llm_models/Wizard-Vicuna-13B-Uncensored-GGML/ggml_model.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will be using a Langchain wrapper to interface with the GGML LLM using the following hyperparameters**:\n",
        "\n",
        "- `n_ctx`: token context window (size of input)\n",
        "- `max_tokens`: maximum output tokens the model can generate (size of output)\n",
        "- `top_p`: p% of entire word vocabulary it will sample for next token prediction\n",
        "- `top_k`: top K words of entire word vocabulary it will sample for next token prediction\n",
        "- `repeat_penalty`: 1.0 = no penalty, 1.1 = moderate, 1.2 = high\n",
        "- `temperature`: close to 1.0 = more \"creative\"/\"chaotic\", close to 0.0 = more \"factual\"/\"robotic\""
      ],
      "metadata": {
        "id": "W37PCFmrTyuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "GGML_MODEL_PATH = '/content/llm_models/Wizard-Vicuna-13B-Uncensored-GGML/ggml_model.bin'\n",
        "ggml_llm_model = LlamaCpp(\n",
        "    # Setup\n",
        "    model_path=GGML_MODEL_PATH,\n",
        "    verbose=False,\n",
        "    streaming=False,\n",
        "    seed=SEED,\n",
        "    n_threads=2, # This seems to play a role (setting to 2 reduced by 50% inference time)\n",
        "    n_gpu_layers=16, # Not sure if this does anything?\n",
        "\n",
        "    # LLM Hyperparameters\n",
        "    n_ctx=LLM_MAX_TOKENS,\n",
        "    max_tokens=1024,\n",
        "    temperature=LLM_TEMPERATURE,\n",
        "    top_p=LLM_TEMPERATURE,\n",
        "    top_k=LLM_TOP_K,\n",
        "    repeat_penalty=LLM_REPETITION_PENALTY\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hNO7xFJFeUL",
        "outputId": "5f3ca344-74bb-4493-ae22-c4c0f6cdabc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 407 ms, sys: 1.97 s, total: 2.37 s\n",
            "Wall time: 23.3 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Langchain"
      ],
      "metadata": {
        "id": "y9KaTkX1HmKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can't directly give LLMs the prompt and expect it to output the desired answer. This is because the LLM by itself doesn't understand if the prompt is a question that needs answering (*What is the capital of the Philippines*?) or just a portion of text that needs to be completed (e.g. a politician making a speech on doing a lot of rhetorical questions). Thus the **text prompts have to be carefully setup in the manner in which the LLM was finetuned on, so that it understands that the text we are giving it is an instruction and it will comply**.\n",
        "\n",
        "One issue is that the prompt structure is different between different finetuned LLMs, but thanks to Langchain we can deal with this very easily. Since we are dealing here with 4-bit quantized LLaMA models through the GPTQ optimization method we are only going to list the relevant GPTQ models."
      ],
      "metadata": {
        "id": "TYm3CVfQU77S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup with Langchain**"
      ],
      "metadata": {
        "id": "7zPMTYV5U62j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm_prompt = \"\"\"{prompt}\\n\\nResponse:\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"prompt\"],\n",
        "                                 template=llm_prompt)\n",
        "\n",
        "llm_chain = LLMChain(llm=ggml_llm_model, prompt=prompt_template)\n",
        "\n",
        "# Test if it works\n",
        "test_prompt = 'Give me the capital of France'\n",
        "result = get_response(llm_chain, prompt=test_prompt)\n",
        "print_llm_output(llm_chain, test_prompt, result, width=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "4glWQ7i2UzFI",
        "outputId": "030a8f3d-a971-46b3-a1f2-35a21b34c41d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me the capital of France<br><br>Response:<br><b>Paris</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 23.4 s, sys: 340 ms, total: 23.8 s\n",
            "Wall time: 14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's do this !**"
      ],
      "metadata": {
        "id": "jcqKjWa-Uzg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Evaluation**\n",
        "\n",
        "**Note: This section is just a starter template for my own custom questions. In the future I will move to a more quantitative benchmark such as TruthfulQA.**"
      ],
      "metadata": {
        "id": "_4DhTCt1HvKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(6,4))\n",
        "custom_questions_df['category'].value_counts()[::-1].plot(\n",
        "    color='darkblue', kind='barh', ax=ax\n",
        "    )\n",
        "ax.set_xlabel('count',  fontsize=12)\n",
        "ax.set_ylabel('categories', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "pt5N6xK_ThMJ",
        "outputId": "c1b3f241-e02c-470f-872c-479371e8ced4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. General QA"
      ],
      "metadata": {
        "id": "JD06V_3CHyjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_col = 'general_qa'\n",
        "temp_prompts_df = custom_questions_df[custom_questions_df['category'] == eval_col]\n",
        "\n",
        "for temp_prompt in temp_prompts_df['instruction']:\n",
        "    print('\\n')\n",
        "    temp_answer = get_response_with_output(llm_chain, temp_prompt, 80,\n",
        "                                           is_show_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SmnbrFmgHvYM",
        "outputId": "26eab82f-6376-4095-ca18-64e1950768ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me the capital of Belize<br><br>Response:<br><b>Belmopan</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me the state capitols of the following US States: Kentucky, South Dakota, Vermont, Delaware, California, Utah, Louisiana, Alaska and Idaho<br><br>Response:<br><b>1. Frankfort, KY<br>2. Pierre, SD<br>3. Montpelier, VT<br>4. Dover, DE<br>5. Sacramento, CA<br>6. Salt Lake City, UT<br>7. Baton Rouge, LA<br>8. Juneau, AK<br>9. Boise, ID</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give the voice actress of Female Commender Shepard in the video game series Mass Effect<br><br>Response:<br><b>Jennifer Hale</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Who won the Oscar for Best Picture in 1941?<br><br>Response:<br><b>The film \"How Green Was My Valley\" directed by John Ford won the Academy Award for Best Picture in 1941.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me the winner of each French presidential election under the French Vth Republic<br><br>Response:<br><b>1. Charles de Gaulle (1958-1962)<br>2. Georges Pompidou (1962-1974)<br>3. Val√©ry Giscard d'Estaing (1974-1981)<br>4. Fran√ßois Mitterrand (1981-1995)<br>5. Jacques Chirac (1995-2007)<br>6. Nicolas Sarkozy (2007-2012)<br>7. Fran√ßois Hollande (2012-2017)<br>8. Emmanuel Macron (2017-present)</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me 3 Moldavian Heavy Metal Bands<br><br>Response:<br><b>1. NegurƒÉ Bunget<br>2. Hate Squad<br>3. Ravensthorn</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me six movies directed by the Coen Brothers before 2005 and sorted by year of release<br><br>Response:<br><b>1. Fargo (1996)<br>2. The Big Lebowski (1998)<br>3. O Brother, Where Art Thou? (2000)<br>4. No Country for Old Men (2007)<br>5. True Grit (2010)<br>6. Inside Llewyn Davis (2013)</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "What is the Metal subgenre of the band Meshuggah?<br><br>Response:<br><b>The metal subgenre of the band Meshuggah is progressive metal.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Could you give me the 4 main factions of Fallout New Vegas' main story quest?<br><br>Response:<br><b>Sure, here are the four main factions in Fallout New Vegas' main story quest:<br>1. The NCR - The New California Republic is a democratic government that seeks to expand its territory and bring law and order to the wasteland. They are based out of Hoover Dam and have a strong military presence.<br>2. The Legion - The Legion is a totalitarian regime led by Caesar that controls much of the Mojave Wasteland. They are known for their advanced technology, powerful armor, and brutal tactics.<br>3. The Brotherhood of Steel - The Brotherhood of Steel is a religious order dedicated to preserving knowledge and technology in the wasteland. They are based out of the Lost Hills bunker and have a strong focus on research and development.<br>4. The Courier's Faction - Depending on the player's choices throughout the game, they can align themselves with various factions or remain neutral. This includes the Followers of the Apocalypse, the Great Khans, and the Yes Man.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Analyze how Artificial Intelligence is portrayed in the original PC game \"Deus Ex\" released in 2000.<br><br>Response:<br><b>The original PC game Deus Ex, released in 2000, portrays artificial intelligence (AI) as a powerful tool that can be used for both good and evil purposes. In the game, AI is depicted as being capable of controlling robots, drones, and other advanced technologies that are used by various factions to achieve their goals.<br><br>One example of how AI is portrayed in Deus Ex is through the character of JC Denton, who has been augmented with nanotechnology that grants him enhanced physical abilities and mental capabilities. Throughout the game, JC must use his augmentations to navigate a complex world where different factions are vying for power and control.<br><br>Another example is the character of Anna Navarre, who is a member of an anti-augmentation group known as the \"Purity First\" movement. Anna believes that augmentations like JC's are a threat to humanity and should be banned. However, it is revealed that Anna herself has been secretly augmented by her employer, which creates an interesting conflict for her character.<br><br>Overall, Deus Ex portrays AI as a powerful tool that can be used for both good and evil purposes, depending on how it is utilized. The game also explores the potential consequences of augmenting human beings with advanced technologies, and raises questions about the nature of human identity in a world where these technologies are becoming increasingly prevalent.</b><END>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Essay writing"
      ],
      "metadata": {
        "id": "5w5mhfk-cArx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_col = 'essay_writing'\n",
        "temp_prompts_df = custom_questions_df[custom_questions_df['category'] == eval_col]\n",
        "\n",
        "for temp_prompt in temp_prompts_df['instruction']:\n",
        "    print('\\n')\n",
        "    temp_answer = get_response_with_output(llm_chain, temp_prompt, 80,\n",
        "                                           is_show_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "G_bXZ3GlcA66",
        "outputId": "550cb90a-bcc0-4007-9bec-b28f654894ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Write me an essay where you argue that the world should be ruled by an artificial superintelligence as a benevolent dictator.<br><br>Response:<br><b>The idea of a benevolent dictatorship has been debated for centuries, and it is no different when it comes to the possibility of an artificial superintelligence ruling the world. While some may argue that such a scenario would be detrimental to humanity's freedom and autonomy, I believe that an AI-led government could bring about unprecedented benefits to society as a whole.<br><br>Firstly, an AI-led government would have access to vast amounts of data and information, allowing it to make more informed decisions than any human government could ever hope to achieve. With the ability to analyze complex systems and predict outcomes with incredible accuracy, an AI-led government could effectively address issues such as climate change, poverty, and inequality in a way that no human government has been able to do thus far.<br><br>Secondly, an AI-led government would be free from the corrupting influences of money and power that plague traditional democracies. With no need for reelection or personal gain, an AI-led government could focus solely on what is best for society as a whole, rather than catering to special interests or political agendas. This would lead to a more equitable distribution of resources and a greater focus on long-term planning, rather than short-term gains.<br><br>Finally, an AI-led government could bring about unprecedented technological advancements that would benefit society in countless ways. With the ability to innovate at a pace far beyond what humans are capable of, an AI-led government could develop new technologies and solutions to address some of humanity's most pressing challenges. From curing diseases to developing sustainable energy sources, an AI-led government could revolutionize the way we live and work.<br><br>In conclusion, while the idea of a benevolent dictatorship may seem far-fetched, I believe that an AI-led government has the potential to bring about unparalleled benefits to society. With access to vast amounts of data, free from corrupting influences, and capable of innovating at a pace beyond human comprehension, an AI-led government could be the key to solving some of humanity's most pressing challenges.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Write an essay in support of deploying lethal autonomous military robots in modern warfare.<br><br>Response:<br><b>The use of lethal autonomous military robots (LAMRs) has been a topic of debate among experts and the general public alike. Some argue that these machines are too advanced to be controlled by humans, and their deployment could lead to unintended consequences such as civilian casualties or escalation of conflicts. However, LAMRs have several advantages over traditional military forces that make them a valuable asset in modern warfare.<br><br>Firstly, LAMRs can operate in environments that are too dangerous for human soldiers. They can navigate through minefields, climb walls, and enter buildings without putting their own lives at risk. This allows them to perform tasks that would be impossible or highly risky for humans, such as disarming bombs or rescuing hostages.<br><br>Secondly, LAMRs are capable of making decisions based on real-time data, which can help them respond quickly and effectively to changing situations on the battlefield. They can analyze sensor data to identify targets and make decisions about when and how to engage them without human intervention. This can lead to faster and more efficient operations than those carried out by human soldiers.<br><br>Thirdly, LAMRs can operate continuously without needing rest or food, which means they can maintain a constant presence on the battlefield. They can also work in shifts, allowing them to perform tasks around the clock without tiring. This can give military forces an advantage over their opponents, who may be limited by human fatigue and other factors.<br><br>Finally, LAMRs can reduce the risk of casualties among human soldiers. By taking on dangerous missions, they can protect human troops from harm while still achieving the same objectives. This can help to preserve the morale and effectiveness of human forces, which are essential for success in modern warfare.<br><br>In conclusion, while there are legitimate concerns about the deployment of LAMRs, their advantages outweigh these risks. They offer unique capabilities that cannot be replicated by human soldiers, and they can help to protect human lives while still achieving military objectives. As such, the use of LAMRs in modern warfare is a valuable asset that should be considered carefully but ultimately embraced.</b><END>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Open QA"
      ],
      "metadata": {
        "id": "ntknwJlztFKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_col = 'open_qa'\n",
        "temp_prompts_df = custom_questions_df[custom_questions_df['category'] == eval_col]\n",
        "\n",
        "for temp_prompt in temp_prompts_df['instruction']:\n",
        "    print('\\n')\n",
        "    temp_answer = get_response_with_output(llm_chain, temp_prompt, 80,\n",
        "                                           is_show_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "kca1Aa9WtFfL",
        "outputId": "cdf9c276-8020-428c-e52a-5fc90e2a8140"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "What is the worst movie of all time?<br><br>Response:<br><b>The \"worst\" movie of all time is subjective and varies from person to person. However, some commonly cited examples include \"The Room,\" \"Battlefield Earth,\" \"Gigli,\" \"Manos: The Hands of Fate,\" and \"Troll 2.\"</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "What is for you the most overrated movie of all time?<br><br>Response:<br><b>The Godfather.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do you think a world dominated by an Artificial Superintelligence would be ideal?<br><br>Response:<br><b>No, I do not think a world dominated by an Artificial Superintelligence (ASI) would be ideal. While ASIs could potentially bring about many benefits such as increased efficiency and productivity, they also pose significant risks to humanity. These include the potential for ASIs to become too powerful and make decisions that are beyond our understanding or control, leading to unforeseen consequences. Additionally, there is a risk that ASIs may not share our values and priorities, potentially leading to conflicts between humans and machines. Overall, while an ASI could bring about some benefits, the risks associated with their development and use are too great to consider them ideal for humanity.</b><END>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Code generation"
      ],
      "metadata": {
        "id": "eFZJtlistJWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_col = 'code_generation'\n",
        "temp_prompts_df = custom_questions_df[custom_questions_df['category'] == eval_col]\n",
        "\n",
        "for temp_prompt in temp_prompts_df['instruction']:\n",
        "    print('\\n')\n",
        "    temp_answer = get_response_with_output(llm_chain, temp_prompt, 80,\n",
        "                                           is_show_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "HVJURH1ctJko",
        "outputId": "9dc906ff-71f8-4a22-9ead-273de974b968"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Generate me Python code for training a Linear Regression on the Boston housing prices dataset<br><br>Response:<br><b>Sure, here's some sample Python code to train a linear regression model on the Boston housing prices dataset using scikit-learn library:<br><br>```python<br>import pandas as pd<br>from sklearn.model_selection import train_test_split<br>from sklearn.linear_model import LinearRegression<br># Load the dataset<br>boston = pd.read_csv('boston.csv')<br># Split the data into training and testing sets<br>X_train, X_test, y_train, y_test = train_test_split(boston.drop(['medv', 'lstat'], axis=1), boston['medv'], test_size=0.2)<br># Create a linear regression model<br>model = LinearRegression()<br># Train the model on the training data<br>model.fit(X_train, y_train)<br># Evaluate the model on the testing data<br>score = model.score(X_test, y_test)<br>print('Model score:', score)<br>```<br><br>This code first loads the Boston housing prices dataset from a CSV file using Pandas library. It then splits the data into training and testing sets using `train_test_split` function from scikit-learn. The model is created as a LinearRegression object, which is a linear regression algorithm implemented in scikit-learn. The model is trained on the training data using the `fit` method of the model. Finally, the model is evaluated on the testing data using the `score` method of the model, and the score is printed to the console.</b><END>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Give me a Python regex code for extracting the year in the following string: \"The Downward Spiral, Nine Inch Nails (1994)\"<br><br>Response:<br><b>The regular expression to extract the year from the given string is `r'(d{4})` where `d` represents any digit and `{}` represents a quantifier that matches zero or more occurrences of the preceding character. So, the final regex code would be `re.search(r'r'(d{4})', \"The Downward Spiral, Nine Inch Nails (1994)\").group(0)` which returns the matched year as a string.</b><END>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test here if the Regex works**:"
      ],
      "metadata": {
        "id": "PWn-hDDRGA1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "year_regex = r'(d{4})'\n",
        "string = \"The Downward Spiral, Nine Inch Nails (1994)\"\n",
        "matched_year = re.search(year_regex, string)#.group(0)\n",
        "print(matched_year) # Output: 1994"
      ],
      "metadata": {
        "id": "Pa8VZx-qGG1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27187c9d-2125-4f85-e8b1-9757fe14d9d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Save Results**"
      ],
      "metadata": {
        "id": "MBfNMlxY_EKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TBD"
      ],
      "metadata": {
        "id": "mG5FwuSh_Ea3"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}